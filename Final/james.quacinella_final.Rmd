---
title: "IS624 - Final"
author: "James Quacinella"
date: "07/12/2015"
output: 
  pdf_document:
    toc: yes
theme: journal
---

```{r include=FALSE}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


## Introduction

Originally, I planned on working with a few data sets relating to electrical power generators and their $C0_2$ emissions. I found a few data sets, but a critical data set on world-wide generators is not free sadly. In lieu of working with this data, I found a dataset on the UCI Machine Learning repository that was tangentially related to the original idea. To quote directly from the [data source itself](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant):

>The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years
>(2006-2011), when the power plant was set to work with full load. Features consist of hourly
>average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and
>Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP)  of the plant.
>
>A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and
>heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam
>turbines, which are combined in one cycle, and is transferred from one turbine to another.
>While the Vacuum is collected from and has an effect on the Steam Turbine, the other three o
>the ambient variables effect the GT performance.

In this project, I will try to develop predictive models for this dataset. Here, I will try to predict the energy output (EP) of the power plant from the 4 predictors gievn (temperature, ambient pressure, relative humidity and exhaust vaccum). My hypothesis is that models regarding physical processes should be pretty accurate once a proper model is chosen, since physical processes obey physical laws.

I will start with linear regression and see what other models can bring.



## Data Preperation

The first thing to do was convert the .ods file into a .csv file using LibreOffice. The data.csv file is the result, and has been loaded:

```{r results='hide', message=FALSE}
# Init
library(e1071)
library(caret)
library(corrplot)
library(ggplot2)
library(GGally)
library(forecast)

# Set random set for predictability
set.seed(200)

# Load data
df <- read.csv("CCPP/data.csv")
predictors <-  c("V", "AT", "RH", "AP")
#df.predictors <- df[ , c("V", "AT", "RH", "AP")]
#df.predict <- data.frame(PE=df[ , c("PE")])
```

Lets see if there are any non-complete cases in the data:

```{r results='hide'}
sum(complete.cases(df$AT)) == nrow(df) # True
sum(complete.cases(df$V)) == nrow(df)  # True
sum(complete.cases(df$AP)) == nrow(df) # True
sum(complete.cases(df$RH)) == nrow(df) # True
```

It looks like we have a full data set with no missing NA values. Lets see if any of the predictors are significantly skewed:

```{r}
skewValues <- apply(df[, predictors], 2, skewness)
head(skewValues)
```

From this I would say that there is no significant skewness here, so Box Cox transformations are not needed.

TODO: 
* should we transform via center and scaling?


Lets remove any near zero variance predictors:

```{r}
remove <- nearZeroVar(df[ , predictors])   # No columns are near zero variance
```

Are there any correlations between predictors?

```{r}
correlations <- cor(df[ , predictors])
corrplot::corrplot(correlations, order = "hclust")
```

From this we can see some correlations between predictors, but that might be normal: the operating conditions of the plant probably change according to fundamental physical laws and operating contraints, so their changes over time might be correlated.

Lets view that data:

```{r}
ggpairs(df[ , predictors])

p1 <- ggplot(df, aes(x=AT, y=PE)) + geom_point() + geom_smooth(method='lm') + ggtitle("Output versus Ambient Temperature") + ylab("Energy Output")
p2 <- ggplot(df, aes(x=AP, y=PE)) + geom_point() + geom_smooth(method='lm') + ggtitle("Output versus Ambient Pressure") + ylab("Energy Output")
p3 <- ggplot(df, aes(x=RH, y=PE)) + geom_point() + geom_smooth(method='lm') + ggtitle("Output versus Relative Humidity") + ylab("Energy Output")
p4 <- ggplot(df, aes(x=V, y=PE)) + geom_point() + geom_smooth(method='lm') + ggtitle("Output versus Exhaust Vacuum") + ylab("Energy Output")
multiplot(p1, p2, p3, p4, cols=2)
```

For the next steps, where we build models for this data, lets create a training and test set for performance measures. I played around with the percentage of data to be used for cross-validation, with 90% used for training being a good value that ends with good results (though the range of values tried always ended up with results with $R^2$ > .9:

```{r}
trainIndex <- createDataPartition(df$PE, p = .9, list=FALSE)
df.training <- df[trainIndex, ]
df.test <- df[-trainIndex, ]
```

## Linear Regression Model

```{r}
# Build Lineat Regression Model
fit  <- lm(PE ~ V + AT + RH + AP, data=df.training)
#summary(fit)

# Residuals
plot(residuals(fit) ~ PE, data=df.training, main="Residuals Plot")
abline(0, 0, col='red')

# Forecast the data
forecast <- forecast(fit, newdata=df.test)
accuracy(forecast, df.test)
postResample(pred = forecast$mean, obs = df.test$PE)

# Plot predictions versus reality in test set
plot(df.test$PE, forecast$mean, main="Predictions of Energy Output versus Test Set\nLinear Regression Model", ylab="Energy Output (Prediction)", xlab="Energy Output (Test Set)")
abline(0, 1, col='red')
```

## Linear Regression Model with Less Predictors

Lets try taking out one of the highly correlated predictors and see if we can improve our model:

```{r}
# Build Linear Regression Model
fit  <- lm(PE ~ V + RH + AP, data=df.training)
#summary(fit)

# Residuals
#plot(residuals(fit) ~ PE, data=df.training, main="Residuals Plot")
#abline(0, 0, col='red')

# Forecast the data
forecast <- forecast(fit, newdata=df.test)
accuracy(forecast, df.test)
postResample(pred = forecast$mean, obs = df.test$PE)

# Plot predictions versus reality in test set
#plot(df.test$PE, forecast$mean, main="Predictions of Energy Output versus Test Set", ylab="Energy Output (Prediction)", xlab="Energy Output (Test Set)")
#abline(0, 1, col='red')
```

Taking out the Ambient Temperature predictor, despite having high correlations to the other predictors, does not seem to help here as it reduces $R^2$ and increases the $RMSE$.

## More Advanced Models

The above model gets a pretty good result, but I'd like to see if another model would improve the correlation coefficient or reduce the RMSE. I decided on using an SVM:

```{r}
# Create a radial kernel SVM with some default params
library(kernlab)
svmFit <- ksvm(PE~ ., data=df, kernel="rbfdot", kpar="automatic", C=1, epsilon=0.1)

# Predict on the test group and look at metrics
svmPredict <- predict(svmFit, df.test)
postResample(pred = svmPredict, obs = df.test$PE)

# Plot predictions versus reality in test set
plot(df.test$PE, svmPredict, main="Predictions of Energy Output versus Test Set\nSVM Model", ylab="Energy Output (Prediction)", xlab="Energy Output (Test Set)")
abline(0, 1, col='red')
```

This model does a little bit better with a slightly lower RMSE and slightly higher $R^2$. This may indicate that the data truly is linear in nature and adding non-linearities will not help that much in improving the model.

## Results

Generally, these resulting models look pretty good from an $RMSE$ and $R^2$ persepctive. The plots of the response from the model versus the actual response in the data do follow a straight line with the range of the residuals not being large compared to the data values:

```{r}
hist(svmPredict - df.test$PE, main="Residuals of SVM Model on Test Set", xlab="Residual")
range <- range(df.test$PE)
legend(8, 300, paste("range of output\n", range[1], " - ", range[2]))
```

As we can see, the residuals are pretty evenly distributed around 0, with the majority of residuals between -10 and 10, which is ~7% of the output range. I would say that these models have a very good distribution of errors.

## Things to Think About for Future Modeling

- What if the response (energy output) is related to these values but a 'lagged' version of the predictors? Meaning, a $\Delta T$ increase in temperature may not affect the energy output until enough time has passed for it to take effect. The lack of timing information, or data that is more 'realtime', prevents us from looking into this.

- Seasonal effects: the time of the year mat affect energy output (consumer demand, weather / climate) but once again, lack of timing data prevents us from doing this. Otherwise, time series models may have been useful.

## Errors

Where can errors stem from in this model / problem:

- Faulty sensors that are recording the 4 predictor values
- As explained above, if there is any 'lag' in the relationship between  the predictors and eneergy output, we cannot model it here due to a lack of data

## Citations

Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615, http://dx.doi.org/10.1016/j.ijepes.2014.02.027.
(http://www.sciencedirect.com/science/article/pii/S0142061514000908)

Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai)